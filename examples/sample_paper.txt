An Innovative Self-Reliant Framework for Multi-Stage Summarization of Long Scientific Documents

Abstract

Scientific literature continues to grow exponentially, creating challenges for researchers to stay current with relevant findings. This paper presents a novel two-phase hierarchical framework for automatic summarization of long scientific documents. Our approach combines keyphrase extraction, contrastive learning-enhanced semantic representations, and large language model integration to generate coherent, informative summaries. Unlike existing methods that require extensive fine-tuning or domain-specific training data, our framework operates in a self-reliant manner using pre-trained models. We evaluate our system on 100+ biomedical research articles from PubMed, demonstrating ROUGE-L F1 scores of 0.45 for section-level summaries and 0.40 for document-level summaries. The framework achieves compression ratios of 75-80% while preserving critical scientific terminology, numerical results, and citation integrity.

Introduction

The volume of scientific publications has grown dramatically over the past decades, with millions of new research papers published annually. Researchers face increasing difficulty in keeping pace with relevant literature in their fields. While abstract-only summarization has been extensively studied, most scientific papers contain 8,000+ words distributed across multiple sections (Introduction, Methods, Results, Discussion, Conclusion), each serving distinct rhetorical purposes. Effective summarization must respect this hierarchical structure and allocate appropriate attention to sections based on their importance.

Existing approaches to document summarization fall into two categories: extractive methods that select important sentences, and abstractive methods that generate new text. Extractive techniques often produce disjointed summaries lacking coherence, while abstractive methods typically require large amounts of training data and substantial computational resources for fine-tuning. Recent advances in large language models (LLMs) such as BART, T5, and GPT have shown promise for abstractive summarization, but their application to long scientific documents remains challenging due to input length limitations and the need to preserve technical accuracy.

Our framework addresses these limitations through a two-phase hierarchical approach. Phase 1 generates section-level summaries by extracting keyphrases, enhancing sentence embeddings through contrastive learning, and applying LLM-based sentence fusion. Phase 2 synthesizes document-level summaries by computing section importance scores, allocating summary budget proportionally, and combining section summaries coherently. This architecture handles documents exceeding typical transformer length limits while maintaining scientific rigor.

Methods

Our framework consists of five main components: text preprocessing, keyphrase extraction, contrastive representation learning, summarization generation, and evaluation. We describe each component in detail.

Text preprocessing begins with section detection using rule-based patterns to identify standard scientific paper sections. We apply scientific text cleaning that preserves important elements such as citations, numerical values, statistical results, and technical terminology while removing artifacts like figure references and URLs. Sentence segmentation uses spaCy with scientific text awareness to handle complex sentence structures common in technical writing.

Keyphrase extraction employs KeyBERT with Maximal Marginal Relevance (MMR) to identify important phrases while maintaining diversity. We dynamically calculate the number of keyphrases based on section length, with a target of approximately one keyphrase per 300 characters. This adaptive approach ensures adequate coverage for long sections while avoiding over-extraction from short sections. The diversity parameter is set to 0.7 to balance relevance and variety in extracted phrases.

Contrastive learning enhances sentence embeddings using InfoNCE loss. We generate positive pairs from sentences within the same section sharing keyphrases, and negative pairs from sentences in different sections. The projection head maps 384-dimensional Sentence-BERT embeddings to 64-dimensional representations optimized for distinguishing semantically similar and dissimilar content. We train for 10 epochs with a learning rate of 1e-4, batch size of 16, and temperature parameter of 0.07. This process improves semantic representations beyond base Sentence-BERT embeddings.

Section importance scoring computes semantic similarity between each section and a reference (typically the abstract). Cosine similarity scores are normalized to the range [0, 1] and used to weight sections during document-level summarization. We apply exponential allocation with alpha=2.0 to distribute summary budget across sections, giving higher-importance sections proportionally more space in the final summary.

LLM-based summarization uses facebook/bart-large-cnn for abstractive text generation. For section-level summaries, we set maximum length based on section importance and target compression ratio. For document-level summaries, we combine section summaries with appropriate formatting. The model operates in zero-shot mode without fine-tuning, relying on its pre-trained capabilities for scientific text understanding.

Results

We evaluated our framework on 100 randomly selected PubMed articles from the biomedical domain, comparing against reference summaries written by domain experts. Articles ranged from 3,000 to 12,000 words with an average length of 7,500 words.

Section-level summarization achieved ROUGE-1 F1 of 0.50, ROUGE-2 F1 of 0.25, and ROUGE-L F1 of 0.45. BERTScore F1 averaged 0.88, indicating strong semantic similarity to reference summaries despite surface-level differences. Average compression ratio was 75%, reducing sections to approximately one-quarter of their original length while retaining key information. Methods and Results sections showed highest ROUGE scores, likely due to their more structured and formulaic language.

Document-level summarization produced ROUGE-1 F1 of 0.44, ROUGE-2 F1 of 0.20, and ROUGE-L F1 of 0.40. BERTScore F1 was 0.84, demonstrating good semantic alignment. Overall compression ratio reached 80%, condensing full documents to approximately one-fifth of original length. The hierarchical approach successfully allocated more summary space to Introduction and Discussion sections, which received higher importance scores.

Ablation studies examined the contribution of each component. Removing contrastive learning reduced ROUGE-L by 0.05, demonstrating the value of enhanced embeddings. Removing keyphrase extraction decreased ROUGE-L by 0.07, highlighting the importance of identifying salient concepts. Using extractive summarization instead of LLM-based generation reduced ROUGE-L by 0.12 and BERTScore by 0.15, confirming the superiority of abstractive approaches for coherence and readability.

Processing time averaged 45 seconds per document on CPU (Intel i7-9700K) and 12 seconds on GPU (NVIDIA RTX 2080), making the framework practical for large-scale applications. Memory usage remained under 4GB, allowing deployment on standard hardware.

Discussion

Our results demonstrate that a self-reliant framework combining multiple pre-trained components can effectively summarize long scientific documents without domain-specific fine-tuning. The two-phase hierarchical approach addresses length limitations of transformer models while respecting the rhetorical structure of scientific papers.

The strong BERTScore results (0.88 for section-level, 0.84 for document-level) indicate that our summaries capture semantic content well, even when using different surface forms than reference summaries. This is particularly important for scientific text, where meaning preservation matters more than exact wording. The lower ROUGE scores compared to BERTScore reflect the abstractive nature of our approach, which rewrites content rather than extracting verbatim sentences.

Contrastive learning proved beneficial for enhancing semantic representations. The InfoNCE loss encourages embeddings of related sentences (positive pairs sharing keyphrases within sections) to cluster together while pushing apart unrelated sentences (negative pairs from different sections). This refinement improves section importance scoring and content selection.

The exponential allocation strategy effectively balances summary space across sections based on importance. Introduction and Discussion typically receive more allocation due to their central role in presenting motivation and interpreting findings. Methods and Results, while important for reproducibility and evidence, can often be compressed more aggressively for general summaries.

Limitations include reliance on clear section structure in input documents and current support only for English-language papers. The framework also inherits any biases present in pre-trained models. Future work should explore multilingual support, handling of atypical document structures, and integration of domain-specific knowledge bases.

Conclusion

We presented a novel self-reliant framework for multi-stage summarization of long scientific documents. Our hierarchical approach combines keyphrase extraction, contrastive learning, and LLM integration to generate coherent, informative summaries without requiring fine-tuning. Evaluation on 100+ biomedical articles demonstrated strong performance (ROUGE-L F1 0.40-0.45, BERTScore F1 0.84-0.88) while achieving 75-80% compression. The framework operates efficiently on standard hardware, making it practical for researchers seeking to process large volumes of scientific literature. Code and data are available at https://github.com/AlirezaKeshavarz99/Scientific-Document-Summarization-Demo for further research and applications.
